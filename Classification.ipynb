{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import packages"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:52:42.994506Z","iopub.status.busy":"2024-02-21T14:52:42.994193Z","iopub.status.idle":"2024-02-21T14:52:58.377502Z","shell.execute_reply":"2024-02-21T14:52:58.376577Z","shell.execute_reply.started":"2024-02-21T14:52:42.994479Z"},"trusted":true},"outputs":[],"source":["import os\n","import random\n","import pandas as pd\n","import numpy as np\n","import cv2\n","import albumentations as A\n","import seaborn as sns\n","sns.set_style('darkgrid')\n","from PIL import Image\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import auc\n","\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras import Sequential\n","from tensorflow.keras import regularizers, layers"]},{"cell_type":"markdown","metadata":{},"source":["# Setup datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:52:58.379731Z","iopub.status.busy":"2024-02-21T14:52:58.379176Z","iopub.status.idle":"2024-02-21T14:52:58.384097Z","shell.execute_reply":"2024-02-21T14:52:58.383027Z","shell.execute_reply.started":"2024-02-21T14:52:58.379703Z"},"trusted":true},"outputs":[],"source":["dataset_name = \"mias\"\n","dataset_paths = [\n","    '/kaggle/input/mias-preprocessed-datasets/datasets/clasify'\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:52:58.385812Z","iopub.status.busy":"2024-02-21T14:52:58.385462Z","iopub.status.idle":"2024-02-21T14:52:58.430705Z","shell.execute_reply":"2024-02-21T14:52:58.429807Z","shell.execute_reply.started":"2024-02-21T14:52:58.385780Z"},"trusted":true},"outputs":[],"source":["IMG_SIZE = 224\n","HIDDEN_LAYERS = [256, 256, 128]\n","USE_HIDDEN_LAYERS = True\n","USE_AUGUMENTATION = False\n","INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n","BATCH_SIZE = 8\n","EPOCHS = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:52:58.433537Z","iopub.status.busy":"2024-02-21T14:52:58.433174Z","iopub.status.idle":"2024-02-21T14:53:10.469702Z","shell.execute_reply":"2024-02-21T14:53:10.468752Z","shell.execute_reply.started":"2024-02-21T14:52:58.433507Z"},"trusted":true},"outputs":[],"source":["from collections import defaultdict\n","\n","count_dist = defaultdict(int)\n","images = []\n","labels = []\n","\n","# Spliting by my self later\n","for path in dataset_paths:\n","    for dirpath, _, filenames in os.walk(path):\n","        for filename in filenames:\n","            \n","            image = cv2.imread(os.path.join(dirpath, filename))\n","            image = cv2.resize(image, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n","            label = dirpath.split('/')[-1]\n","            \n","            count_dist[label] += 1\n","            images.append(image)\n","            labels.append(label)\n","            \n","count_dist"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:10.471066Z","iopub.status.busy":"2024-02-21T14:53:10.470761Z","iopub.status.idle":"2024-02-21T14:53:11.231349Z","shell.execute_reply":"2024-02-21T14:53:11.230469Z","shell.execute_reply.started":"2024-02-21T14:53:10.471041Z"},"trusted":true},"outputs":[],"source":["def visualize_datasets(images, labels, k=4, seed=42):\n","    # visualize datasets\n","    plt.figure(figsize=(20, 20))\n","    random.seed(seed)\n","    samples = random.sample(list(range(len(images))), k)\n","    for stt, i in enumerate(samples):\n","        plt.subplot(2, k, stt + 1)\n","        plt.imshow(images[i])\n","        class_name = labels[i]\n","        plt.title(class_name, color = 'blue' , fontsize=12)\n","        plt.axis('off')\n","\n","    plt.show()\n","\n","visualize_datasets(images, labels)"]},{"cell_type":"markdown","metadata":{},"source":["# Data augumentation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:11.232800Z","iopub.status.busy":"2024-02-21T14:53:11.232481Z","iopub.status.idle":"2024-02-21T14:53:11.258327Z","shell.execute_reply":"2024-02-21T14:53:11.257506Z","shell.execute_reply.started":"2024-02-21T14:53:11.232755Z"},"trusted":true},"outputs":[],"source":["img_augmentation_layers = [\n","    layers.RandomRotation(factor=0.15),\n","    layers.RandomFlip(),\n","    layers.RandomContrast(factor=0.1),\n","]\n","\n","def img_augmentation(images, k=1):\n","    results = []\n","    for i in range(k):\n","        x = images\n","        for layer in img_augmentation_layers:\n","            x = layer(x)\n","        results.extend(x)\n","    \n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:11.259703Z","iopub.status.busy":"2024-02-21T14:53:11.259442Z","iopub.status.idle":"2024-02-21T14:53:19.561110Z","shell.execute_reply":"2024-02-21T14:53:19.560225Z","shell.execute_reply.started":"2024-02-21T14:53:11.259680Z"},"trusted":true},"outputs":[],"source":["data_dict = defaultdict(list)\n","\n","for i, img in enumerate(images):\n","    data_dict[labels[i]].append(img)\n","\n","aug_dict = defaultdict(list)\n","aug_dict['NORMAL'] = img_augmentation(data_dict['NORMAL'], k=10)\n","aug_dict['B'] = img_augmentation(data_dict['B'], k=40)\n","aug_dict['M'] = img_augmentation(data_dict['M'], k=40)\n","\n","all_images = images\n","all_labels = labels\n","for label, items in aug_dict.items():\n","    size = len(items)\n","    aug_labels = [label for i in range(size)]\n","    all_images.extend(items)\n","    all_labels.extend(aug_labels)\n","\n","len(all_images), len(all_labels)"]},{"cell_type":"markdown","metadata":{},"source":["# Encode datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:19.562810Z","iopub.status.busy":"2024-02-21T14:53:19.562440Z","iopub.status.idle":"2024-02-21T14:53:19.567348Z","shell.execute_reply":"2024-02-21T14:53:19.566280Z","shell.execute_reply.started":"2024-02-21T14:53:19.562776Z"},"trusted":true},"outputs":[],"source":["classes = ['NORMAL', 'B', 'M']\n","num_classes = 3"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:19.568924Z","iopub.status.busy":"2024-02-21T14:53:19.568564Z","iopub.status.idle":"2024-02-21T14:53:25.149252Z","shell.execute_reply":"2024-02-21T14:53:25.148293Z","shell.execute_reply.started":"2024-02-21T14:53:19.568895Z"},"trusted":true},"outputs":[],"source":["# Convert labels to numpy array\n","x = np.stack(images, axis=0)\n","y = np.array([classes.index(label) for label in labels])\n","\n","x.shape, y.shape"]},{"cell_type":"markdown","metadata":{},"source":["# Split datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:25.153754Z","iopub.status.busy":"2024-02-21T14:53:25.153452Z","iopub.status.idle":"2024-02-21T14:53:25.158999Z","shell.execute_reply":"2024-02-21T14:53:25.157998Z","shell.execute_reply.started":"2024-02-21T14:53:25.153729Z"},"trusted":true},"outputs":[],"source":["def count_labels(labels):\n","    count_dict = defaultdict(int)\n","    for idx in labels:\n","        count_dict[classes[idx]] += 1\n","    return count_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:25.160155Z","iopub.status.busy":"2024-02-21T14:53:25.159918Z","iopub.status.idle":"2024-02-21T14:53:26.616673Z","shell.execute_reply":"2024-02-21T14:53:26.615688Z","shell.execute_reply.started":"2024-02-21T14:53:25.160128Z"},"trusted":true},"outputs":[],"source":["# Split the data into training and remaining sets (validation + test)\n","x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n","# Split the remaining data into validation and test sets\n","x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n","\n","[\n","    x_train.shape, \n","    x_val.shape, \n","    x_test.shape, \n","    y_train.shape , \n","    y_val.shape , \n","    y_test.shape, \n","    count_labels(y_train),\n","    count_labels(y_val),\n","    count_labels(y_test), \n","]"]},{"cell_type":"markdown","metadata":{},"source":["# Helper functions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:26.617962Z","iopub.status.busy":"2024-02-21T14:53:26.617679Z","iopub.status.idle":"2024-02-21T14:53:26.624164Z","shell.execute_reply":"2024-02-21T14:53:26.623284Z","shell.execute_reply.started":"2024-02-21T14:53:26.617940Z"},"trusted":true},"outputs":[],"source":["def plot_acc(model_history, epochs, name):\n","    print('\\n\\n')\n","    plt.figure(figsize=(12,8))\n","    plt.plot(np.arange(0, epochs), model_history.history[\"accuracy\"], label=\"train_acc\")\n","    plt.plot(np.arange(0, epochs), model_history.history[\"val_accuracy\"], label=\"val_acc\")\n","    plt.title(\"Training Accuracy - {}\".format(name))\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:26.625434Z","iopub.status.busy":"2024-02-21T14:53:26.625170Z","iopub.status.idle":"2024-02-21T14:53:26.635442Z","shell.execute_reply":"2024-02-21T14:53:26.634694Z","shell.execute_reply.started":"2024-02-21T14:53:26.625412Z"},"trusted":true},"outputs":[],"source":["def plot_loss(model_history, epochs, name):\n","    print('\\n\\n')\n","    plt.figure(figsize=(12,8))\n","    plt.plot(np.arange(0, epochs), model_history.history[\"loss\"], label=\"train_loss\", )\n","    plt.plot(np.arange(0, epochs), model_history.history[\"val_loss\"], label=\"val_loss\")\n","    plt.title(\"Training Loss - {}\".format(name))\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:26.636967Z","iopub.status.busy":"2024-02-21T14:53:26.636604Z","iopub.status.idle":"2024-02-21T14:53:26.646139Z","shell.execute_reply":"2024-02-21T14:53:26.645275Z","shell.execute_reply.started":"2024-02-21T14:53:26.636933Z"},"trusted":true},"outputs":[],"source":["# Function to plot confusion matrix\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    \n","    # plot the confusion matrix\n","    class_count = len(classes)\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        \n","    plt.figure(figsize=(12, 8))\n","    sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n","    plt.xticks(np.arange(class_count)+.5, classes, rotation=90)\n","    plt.yticks(np.arange(class_count)+.5, classes, rotation=0)\n","    plt.xlabel(\"Predicted\")\n","    plt.ylabel(\"Actual\")\n","    plt.title(title)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:26.647495Z","iopub.status.busy":"2024-02-21T14:53:26.647209Z","iopub.status.idle":"2024-02-21T14:53:26.659511Z","shell.execute_reply":"2024-02-21T14:53:26.658677Z","shell.execute_reply.started":"2024-02-21T14:53:26.647462Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, x, y):\n","    scores = model.evaluate(x, y, verbose=1)\n","    return scores"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:26.660893Z","iopub.status.busy":"2024-02-21T14:53:26.660534Z","iopub.status.idle":"2024-02-21T14:53:26.670039Z","shell.execute_reply":"2024-02-21T14:53:26.669173Z","shell.execute_reply.started":"2024-02-21T14:53:26.660863Z"},"trusted":true},"outputs":[],"source":["def predict_prob(model):\n","    return model.predict(x_test, batch_size=BATCH_SIZE, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:26.671276Z","iopub.status.busy":"2024-02-21T14:53:26.671016Z","iopub.status.idle":"2024-02-21T14:53:26.680510Z","shell.execute_reply":"2024-02-21T14:53:26.679695Z","shell.execute_reply.started":"2024-02-21T14:53:26.671254Z"},"trusted":true},"outputs":[],"source":["def predict(model):\n","    predictions = predict_prob(model)\n","    return np.argmax(predictions, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:26.681616Z","iopub.status.busy":"2024-02-21T14:53:26.681371Z","iopub.status.idle":"2024-02-21T14:53:26.691333Z","shell.execute_reply":"2024-02-21T14:53:26.690492Z","shell.execute_reply.started":"2024-02-21T14:53:26.681596Z"},"trusted":true},"outputs":[],"source":["def calculate_metrics(y_true, y_pred):\n","    \n","    print(\"Visualize: y_true, y_pred top 20\")\n","    print('Y_true', [i for i in y_true[:20]])\n","    print('Y_pred', [j for j in y_pred[:20]])\n","\n","    # precision tp / (tp + fp)\n","    precision = precision_score(y_true, y_pred, average='weighted')\n","    print(\"Precision: {}\".format(precision))\n","\n","    # recall: tp / (tp + fn)\n","    recall = recall_score(y_true, y_pred, average='weighted')\n","    print(\"Recall:    {}\".format(recall))\n","\n","    # f1: 2 tp / (2 tp + fp + fn)\n","    f1 = f1_score(y_true, y_pred, average='weighted')\n","    print(\"F1:        {}\".format(f1))"]},{"cell_type":"markdown","metadata":{},"source":["# Setup Transfer Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:26.692686Z","iopub.status.busy":"2024-02-21T14:53:26.692418Z","iopub.status.idle":"2024-02-21T14:53:26.703796Z","shell.execute_reply":"2024-02-21T14:53:26.702900Z","shell.execute_reply.started":"2024-02-21T14:53:26.692663Z"},"trusted":true},"outputs":[],"source":["def transfer_learning(model, name):\n","    \n","    best_weights_ph1 = f\"{dataset_name}_{name}_ph1_weights.keras\"\n","    \n","    callbacks_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","        filepath = best_weights_ph1,\n","        monitor = \"val_accuracy\",\n","        mode = \"max\",\n","        save_weights_only=True,\n","        save_best_only = True,\n","        verbose=1, # Logging when callback running\n","    )\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n","    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    history = model.fit(\n","        x_train,\n","        y_train,\n","        batch_size=BATCH_SIZE,\n","        validation_data=(x_val, y_val),\n","        validation_batch_size=BATCH_SIZE,\n","        epochs = EPOCHS,\n","        callbacks = [callbacks_checkpoint]\n","    )\n","    \n","    acc_max = max(history.history[\"accuracy\"])\n","    acc_min = min(history.history[\"accuracy\"])\n","    print(\"Training Acc:\", [acc_min, acc_max])\n","    \n","    val_acc_max = max(history.history[\"val_accuracy\"])\n","    val_acc_min = min(history.history[\"val_accuracy\"])\n","    print(\"Validation Acc:\", [val_acc_min, val_acc_max])\n","    \n","    best_idx = np.argmax(history.history[\"val_accuracy\"])\n","    print('The best val_acc result expected at epoch {} with metrics: '.format(best_idx))\n","    for k, vals in history.history.items():\n","        print('{}: {}'.format(k, vals[best_idx]))\n","    \n","    print('\\nRestoring best weights and predicting validation set.')\n","    model.load_weights(best_weights_ph1)\n","    \n","    loss, acc = evaluate(model, x_test, y_test)\n","    print('Transfer Learning test scores (loss, acc):', [loss, acc])\n","    \n","    plot_acc(history, EPOCHS, f\"\\n Transfer Learning - ACC: {name} PhA.\")\n","    plot_loss(history, EPOCHS, f\"\\n Transfer Learning - LOSS: {name} PhA.\")\n","    \n","    y_pred = predict(model)\n","    return history, model, val_acc_max, y_pred"]},{"cell_type":"markdown","metadata":{},"source":["# Setup fine tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:26.705349Z","iopub.status.busy":"2024-02-21T14:53:26.704875Z","iopub.status.idle":"2024-02-21T14:53:26.719274Z","shell.execute_reply":"2024-02-21T14:53:26.718158Z","shell.execute_reply.started":"2024-02-21T14:53:26.705326Z"},"trusted":true},"outputs":[],"source":["y_train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:26.720919Z","iopub.status.busy":"2024-02-21T14:53:26.720612Z","iopub.status.idle":"2024-02-21T14:53:26.732605Z","shell.execute_reply":"2024-02-21T14:53:26.731758Z","shell.execute_reply.started":"2024-02-21T14:53:26.720897Z"},"trusted":true},"outputs":[],"source":["def fine_turning(model, name, acc_ph1):\n","    \n","    best_weights_ph2 = f\"{dataset_name}_{name}_ph2_weights.keras\"\n","    callbacks_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","        filepath = best_weights_ph2,\n","        monitor = \"val_accuracy\",\n","        mode = \"max\",\n","        save_weights_only=True,\n","        save_best_only = True,\n","        verbose=1, # Logging when callback running\n","    )\n","    \n","    for layer in model.layers[-20:]:\n","        if not isinstance(layer, layers.BatchNormalization):\n","            layer.trainable = True\n","        else:\n","            layer.trainable = False\n","\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n","    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    history = model.fit(\n","        x_train, \n","        y_train,\n","        batch_size=BATCH_SIZE,\n","        validation_data=(x_val, y_val),\n","        validation_batch_size=BATCH_SIZE,\n","        epochs = EPOCHS,\n","        callbacks = [callbacks_checkpoint]\n","    )\n","    \n","    acc_max = max(history.history[\"accuracy\"])\n","    acc_min = min(history.history[\"accuracy\"])\n","    print(\"Training Acc:\", [acc_min, acc_max])\n","    \n","    val_acc_max = max(history.history[\"val_accuracy\"])\n","    val_acc_min = min(history.history[\"val_accuracy\"])\n","    print(\"Validation Acc:\", [val_acc_min, val_acc_max])\n","    \n","    best_idx = np.argmax(history.history[\"val_accuracy\"])\n","    print('The best val_acc result expected at epoch {} with metrics: '.format(best_idx))\n","    for k, vals in history.history.items():\n","        print('{}: {}'.format(k, vals[best_idx]))\n","    \n","    print('Restoring best weights of Ph2 and predicting test set.')\n","    model.load_weights(best_weights_ph2)\n","    loss, acc = evaluate(model, x_test, y_test)\n","    print('Fine Tuning test scores (loss, acc):', [loss, acc])\n","    \n","    if val_acc_max < acc_ph1:\n","        print('\\nPhase 2 resulted in lower accuracy than Phase 1.')\n","    \n","    plot_acc(history, EPOCHS, f\"\\n Fine Turning - ACC: {name} PhB.\")\n","    plot_loss(history, EPOCHS, f\"\\n Fine Turning - LOSS: {name} PhB.\")\n","    \n","    y_pred = predict(model)\n","    return history, model, acc, y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:26.734019Z","iopub.status.busy":"2024-02-21T14:53:26.733695Z","iopub.status.idle":"2024-02-21T14:53:26.746538Z","shell.execute_reply":"2024-02-21T14:53:26.745792Z","shell.execute_reply.started":"2024-02-21T14:53:26.733991Z"},"trusted":true},"outputs":[],"source":["initial_models = dict(\n","    EfficientNetB3=tf.keras.applications.EfficientNetB3,\n","    ResNet50=tf.keras.applications.resnet50.ResNet50,\n","    MobileNet=tf.keras.applications.mobilenet.MobileNet,\n","    InceptionV3=tf.keras.applications.inception_v3.InceptionV3\n",")\n","\n","base_model_kwargs = dict(\n","    include_top=False,\n","    weights='imagenet',\n","    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",")\n","\n","# custom kwargs for each model here \n","initial_models_kwargs = dict(\n","    EfficientNetB3={ **base_model_kwargs },\n","    ResNet50={ **base_model_kwargs },\n","    MobileNet={ **base_model_kwargs },\n","    InceptionV3={ **base_model_kwargs }\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-21T14:53:26.747756Z","iopub.status.busy":"2024-02-21T14:53:26.747494Z","iopub.status.idle":"2024-02-21T16:13:14.500802Z","shell.execute_reply":"2024-02-21T16:13:14.499297Z","shell.execute_reply.started":"2024-02-21T14:53:26.747735Z"},"trusted":true},"outputs":[],"source":["for name, Model in initial_models.items():\n","    \n","    base_model = Model(**initial_models_kwargs[name])\n","    base_model.trainable = False\n","        \n","    output = base_model.output\n","    top_layers = [\n","        layers.GlobalMaxPooling2D(),\n","        layers.BatchNormalization(),\n","        layers.Dropout(0.2),\n","    ]\n","    \n","    if USE_HIDDEN_LAYERS:\n","        for i, layer in enumerate(HIDDEN_LAYERS):\n","            top_layers.append(layers.Dense(layer, activation='relu'))\n","            top_layers.append(layers.BatchNormalization())\n","            top_layers.append(layers.Dropout(0.15))\n","    \n","    top_layers.append(layers.Dense(len(classes), activation='softmax'))\n","    \n","    for layer in top_layers:\n","        output = layer(output)\n","    \n","    model = tf.keras.models.Model(base_model.input, output, name=name)\n","    \n","    print(f'\\n\\n ==========Start Process with model {name}=========')\n","    # model.summary()\n","    \n","    history, model, best_acc_ph1, y_pred = transfer_learning(model, name)\n","    calculate_metrics(y_test, y_pred)\n","    cm = confusion_matrix(y_test, y_pred)\n","    plot_confusion_matrix(cm, classes, title=f\"Confusion matrix for {name} - Transfer Learning\")\n","    \n","    \n","    if best_acc_ph1 < 1.00:\n","        history, model, best_acc_ph2, y_pred = fine_turning(model, name, best_acc_ph1)\n","        calculate_metrics(y_test, y_pred)\n","        cm = confusion_matrix(y_test, y_pred)\n","        plot_confusion_matrix(cm, classes, title=f\"Confusion matrix for {name} - Fine Turnning\")\n","        \n","    else:\n","        print('Transfer learning have 100% accuracy so no need to do fine-turning.')\n","    \n","    print(f'==========End Process with model {name}==========\\n\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4305125,"sourceId":7496577,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
